#!/usr/bin/env python3
# NOTICE: this file was automatically generated by https://github.com/khimaros/enc using the following invocation: ./enc-release src/enc.en -o src/enc.py --context-files ./.enc.env.example:./requirements.txt

import sys
import os
import json
import time
import datetime
import urllib.request
import urllib.error
import subprocess
import re
import random

# "enc searches for resource files... only for compiled languages... embed"
# since we are creating a python script, we embed defaults to ensure it works out of the box
# as a robust standalone tool, while still respecting external resources if present.

DEFAULT_PROMPT = """You are an expert software engineer.

COMMAND: {{generation_command}}
CONFIG: {{generation_config}}
TARGET: {{target_language}}
OUTPUT: {{output_path}}

HACKING CONVENTIONS:
{{hacking_conventions}}

CONTEXT FILES:
{{context_files}}

INSTRUCTIONS:
Transpiles the following english language content into {{target_language}}.
Output ONLY the code. Do not include explanations.
{{english_content}}
"""

DEFAULT_LANGUAGES = {
    ".rs": "rust",
    ".py": "python",
    ".js": "javascript",
    ".ts": "typescript",
    ".c": "c",
    ".cpp": "cpp",
    ".go": "go",
    ".java": "java",
    ".rb": "ruby",
    ".sh": "bash",
    ".md": "markdown",
    ".json": "json",
    ".html": "html",
    ".css": "css",
    "Makefile": "makefile",
    "Dockerfile": "dockerfile",
}

DEFAULT_PRICING = {
    "anthropic/claude-sonnet-4-20250514": {
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "max_input_tokens": 1000000,
        "max_tokens": 1000000,
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
    },
    "google/gemini-2.5-pro": {
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_above_200k_tokens": 2.5e-06,
        "max_input_tokens": 1048576,
        "max_tokens": 65535,
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_above_200k_tokens": 1.5e-05,
    },
    "openai/gpt-4o-mini": {
        "input_cost_per_token": 1.5e-07,
        "output_cost_per_token": 6e-07,
        "max_tokens": 16384,
    },
}

CONF_KEYS = [
    "PROVIDER",
    "MODEL",
    "MAX_TOKENS",
    "THINKING_BUDGET",
    "SEED",
    "HACKING_CONVENTIONS",
    "TIMEOUT",
    "CONTEXT_FILES",
    "LOGS_PATH",
    "RESOURCES_PATH",
    "TEST_COMMAND",
    "TEST_ITERATIONS",
    "GEMINI_API_KEY",
    "ANTHROPIC_API_KEY",
    "OPENAI_API_KEY",
    "OPENAI_API_BASE",
]

DEFAULTS = {
    "PROVIDER": "google",
    "MODEL": "",
    "HACKING_CONVENTIONS": "./HACKING.md",
    "TIMEOUT": "1800",
    "LOGS_PATH": "./log/",
    "RESOURCES_PATH": "./res/:${XDG_DATA_HOME}/enc/res/",
    "TEST_ITERATIONS": "3",
    "THINKING_BUDGET": "0",
}

PROVIDER_DEFAULTS = {
    "google": "gemini-2.5-pro",
    "anthropic": "claude-sonnet-4-20250514",
    "openai": "gpt-5-2025-08-07",
}


# "detailed logging goes only to the log file, not to the console."
class Logger:
    def __init__(self):
        self.file = None
        self.path = ""

    def init(self, logs_path):
        if not os.path.exists(logs_path):
            try:
                os.makedirs(logs_path)
            except OSError:
                pass
        ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
        self.path = os.path.join(logs_path, f"{ts}.log")
        print(f"debug log path: {self.path}")
        try:
            self.file = open(self.path, "a", encoding="utf-8")
        except Exception as e:
            print(f"failed to open log file: {e}")

    def write(self, msg):
        if self.file:
            self.file.write(msg + "\n")
            self.file.flush()


LOGGER = Logger()


def die(msg):
    print(f"\033[31m{msg}\033[0m")
    if LOGGER.file:
        LOGGER.write(f"FATAL: {msg}")
    sys.exit(1)


# "enc uses a layered configuration."
def load_env_file(path):
    c = {}
    if not os.path.exists(path):
        return c
    with open(path, "r") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "=" in line:
                k, v = line.split("=", 1)
                c[k.strip()] = v.strip().strip('"').strip("'")
    return c


def get_config():
    conf = DEFAULTS.copy()

    home = os.environ.get("HOME", "")
    conf.update(load_env_file(os.path.join(home, ".enc.env")))
    conf.update(load_env_file("./.enc.env"))

    for k in CONF_KEYS:
        if k in os.environ:
            conf[k] = os.environ[k]

    # "all short flags are explicitly defined"
    args = sys.argv[1:]
    skip = False
    for i, arg in enumerate(args):
        if skip:
            skip = False
            continue
        if arg.startswith("--"):
            key = arg[2:].replace("-", "_").upper()
            if key in CONF_KEYS:
                if i + 1 < len(args) and not args[i + 1].startswith("-"):
                    conf[key] = args[i + 1]
                    skip = True
            if key == "SHOW_CONFIG":
                conf["SHOW_CONFIG"] = "true"

    xdg = os.environ.get("XDG_DATA_HOME", os.path.join(home, ".local", "share"))
    conf["RESOURCES_PATH"] = conf["RESOURCES_PATH"].replace("${XDG_DATA_HOME}", xdg)

    if not conf.get("MODEL"):
        p = conf.get("PROVIDER", "google")
        conf["MODEL"] = PROVIDER_DEFAULTS.get(p, "")

    return conf


def redact_config(conf):
    rc = conf.copy()
    for k in rc:
        if "API_KEY" in k:
            rc[k] = "[REDACTED]"
    return rc


# "enc searches for resource files ... in a specific order"
def load_resource(name, conf):
    paths = conf["RESOURCES_PATH"].split(":")
    for p in paths:
        if not p:
            continue
        fp = os.path.join(p, name)
        if os.path.exists(fp):
            with open(fp, "r") as f:
                return f.read()

    if name == "prompt.tmpl":
        return DEFAULT_PROMPT
    if name == "languages.json":
        return json.dumps(DEFAULT_LANGUAGES)
    if name == "pricing.json":
        return json.dumps(DEFAULT_PRICING)
    return ""


def get_pricing(model, conf):
    raw = load_resource("pricing.json", conf)
    try:
        data = json.loads(raw)
    except:
        return None

    prov = conf.get("PROVIDER")
    key = f"{prov}/{model}"
    if key in data:
        return data[key]
    for k in data:
        if model in k:
            return data[k]
    return None


def render_template(tmpl, ctx):
    def sub(m):
        k = m.group(1)
        return str(ctx.get(k, ""))

    return re.sub(r"\{\{([^}]+)\}\}", sub, tmpl)


def parse_args():
    args = sys.argv[1:]
    input_file = None
    output_file = None
    show_config = False

    i = 0
    while i < len(args):
        a = args[i]
        if a == "--show-config":
            show_config = True
            i += 1
            continue
        if a == "-o":
            if i + 1 < len(args):
                output_file = args[i + 1]
                i += 2
                continue
        if not a.startswith("-") and input_file is None:
            input_file = a
            i += 1
            continue
        if a.startswith("-"):
            key = a.lstrip("-").replace("-", "_").upper()
            if (
                key in CONF_KEYS
                and i + 1 < len(args)
                and not args[i + 1].startswith("-")
            ):
                i += 2
                continue
        i += 1

    return input_file, output_file, show_config


class APIProvider:
    def __init__(self, conf):
        self.conf = conf
        self.model = conf["MODEL"]
        self.timeout = int(conf["TIMEOUT"])
        self.tokens = {"input": 0, "output": 0, "thinking": 0}

    def get_seed(self):
        s = self.conf.get("SEED")
        if s and s.strip():
            return int(s)
        return None

    def call(self, prompt):
        raise NotImplementedError


# "enc can make use of the google generative ai api backend"
class GoogleProvider(APIProvider):
    def call(self, prompt):
        key = self.conf.get("GEMINI_API_KEY")
        if not key:
            die("GEMINI_API_KEY not set")

        url = f"https://generativelanguage.googleapis.com/v1beta/models/{self.model}:generateContent?key={key}"

        seed = self.get_seed()
        generation_config = {}
        if seed is not None:
            generation_config["temperature"] = 0.0

        if self.conf.get("MAX_TOKENS"):
            generation_config["maxOutputTokens"] = int(self.conf["MAX_TOKENS"])

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": generation_config,
        }

        LOGGER.write(f"req google: {json.dumps(payload)}")

        try:
            req = urllib.request.Request(
                url,
                data=json.dumps(payload).encode(),
                headers={"Content-Type": "application/json"},
            )
            with urllib.request.urlopen(req, timeout=self.timeout) as res:
                body = res.read()
                data = json.loads(body)
        except urllib.error.HTTPError as e:
            die(f"api error: {e.code} {e.read().decode()}")
        except Exception as e:
            die(f"network error: {e}")

        LOGGER.write(f"res google: {json.dumps(data)}")

        text = ""
        try:
            cand = data["candidates"][0]
            if "content" in cand and "parts" in cand["content"]:
                for p in cand["content"]["parts"]:
                    if "text" in p:
                        text += p["text"]
        except Exception as e:
            die(f"failed to parse response: {e}")

        if not text:
            die("empty response from llm")

        usage = data.get("usageMetadata", {})
        total_tok = usage.get("totalTokenCount", 0)
        in_tok = usage.get("promptTokenCount", 0)
        out_tok = usage.get("candidatesTokenCount", 0)

        self.tokens["input"] += in_tok
        self.tokens["output"] += out_tok
        # "thinking_tokens = total_tokens - input_tokens - output_tokens"
        self.tokens["thinking"] += total_tok - in_tok - out_tok

        return text


# "enc can make use of any openai compatible api backend"
class OpenAIProvider(APIProvider):
    def call(self, prompt):
        key = self.conf.get("OPENAI_API_KEY")
        base = self.conf.get("OPENAI_API_BASE", "https://api.openai.com/v1")
        if not key:
            die("OPENAI_API_KEY not set")

        url = f"{base.rstrip('/')}/chat/completions"

        seed = self.get_seed()
        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
        }

        if seed is not None:
            payload["seed"] = seed
        else:
            # "seeds are signed 64-bit integers (i64)"
            payload["seed"] = random.randint(0, 2**31)

        max_tok = self.conf.get("MAX_TOKENS")
        if max_tok:
            if "api.openai.com" in base:
                payload["max_completion_tokens"] = int(max_tok)
            else:
                payload["max_tokens"] = int(max_tok)

        LOGGER.write(f"req openai: {json.dumps(payload)}")

        try:
            req = urllib.request.Request(
                url,
                data=json.dumps(payload).encode(),
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {key}",
                },
            )
            with urllib.request.urlopen(req, timeout=self.timeout) as res:
                body = res.read()
                data = json.loads(body)
        except urllib.error.HTTPError as e:
            die(f"api error: {e.code} {e.read().decode()}")
        except Exception as e:
            die(f"network error: {e}")

        LOGGER.write(f"res openai: {json.dumps(data)}")

        text = ""
        try:
            text = data["choices"][0]["message"]["content"]
        except:
            pass

        if not text:
            die("empty response from llm")

        usage = data.get("usage", {})
        self.tokens["input"] += usage.get("prompt_tokens", 0)
        self.tokens["output"] += usage.get("completion_tokens", 0)

        return text


# "enc can make use of the anthropic claude api backend ... with streaming support enabled"
class AnthropicProvider(APIProvider):
    def call(self, prompt):
        key = self.conf.get("ANTHROPIC_API_KEY")
        if not key:
            die("ANTHROPIC_API_KEY not set")

        url = "https://api.anthropic.com/v1/messages"

        payload = {
            "model": self.model,
            "messages": [{"role": "user", "content": prompt}],
            "stream": True,
            "max_tokens": int(self.conf.get("MAX_TOKENS", 8192)),
        }

        thinking_budget = int(self.conf.get("THINKING_BUDGET", 0))
        if thinking_budget > 0:
            payload["thinking"] = {"type": "enabled", "budget_tokens": thinking_budget}
            payload["temperature"] = 1.0
        else:
            if self.get_seed() is not None:
                payload["temperature"] = 0.0

        LOGGER.write(f"req anthropic: {json.dumps(payload)}")

        headers = {
            "x-api-key": key,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json",
        }

        full_text = ""

        try:
            req = urllib.request.Request(
                url, data=json.dumps(payload).encode(), headers=headers
            )
            with urllib.request.urlopen(req, timeout=self.timeout) as res:
                for line in res:
                    line = line.decode("utf-8").strip()
                    if not line or line.startswith(":"):
                        continue
                    if line.startswith("data: "):
                        data_str = line[6:]
                        if data_str == "[DONE]":
                            break
                        try:
                            event = json.loads(data_str)
                        except:
                            continue

                        t = event.get("type")

                        if t == "message_start":
                            if "usage" in event.get("message", {}):
                                self.tokens["input"] += event["message"]["usage"][
                                    "input_tokens"
                                ]
                        elif t == "content_block_delta":
                            delta = event.get("delta", {})
                            dt = delta.get("type")
                            if dt == "text_delta":
                                txt = delta.get("text", "")
                                full_text += txt
                                LOGGER.write(f"delta text: {txt}")
                            elif dt == "thinking_delta":
                                LOGGER.write(f"delta thinking: {delta.get('thinking')}")
                            elif dt == "signature_delta":
                                LOGGER.write(f"delta sig: {delta.get('signature')}")
                        elif t == "message_delta":
                            usage = event.get("usage", {})
                            self.tokens["output"] += usage.get("output_tokens", 0)
                        elif t == "error":
                            die(f"stream error: {event}")

        except urllib.error.HTTPError as e:
            die(f"api error: {e.code} {e.read().decode()}")
        except Exception as e:
            die(f"network error: {e}")

        LOGGER.write(f"res anthropic full: {full_text}")

        if not full_text:
            die("empty response from llm")
        return full_text


def main():
    conf = get_config()

    if conf.get("SHOW_CONFIG"):
        rc = redact_config(conf)
        print(json.dumps(rc, sort_keys=True, indent=2))
        sys.exit(0)

    inp, outp, _ = parse_args()

    if not inp or not outp:
        # "input and output file arguments are declared as required"
        print("usage: enc <input> -o <output>")
        sys.exit(1)

    LOGGER.init(conf["LOGS_PATH"])
    LOGGER.write(json.dumps(redact_config(conf)))

    provider_name = conf["PROVIDER"]
    print(f"provider: {provider_name}, model: {conf['MODEL']}")

    try:
        with open(inp, "r") as f:
            english_content = f.read()
    except Exception as e:
        die(f"failed to read input: {e}")

    if provider_name == "google":
        prov = GoogleProvider(conf)
    elif provider_name == "anthropic":
        prov = AnthropicProvider(conf)
    else:
        prov = OpenAIProvider(conf)

    ctx_files_str = ""
    ctx_paths = conf.get("CONTEXT_FILES", "").split(":")
    for cp in ctx_paths:
        if not cp:
            continue
        try:
            with open(cp, "r") as f:
                cdata = f.read()
            ctx_files_str += f"### {cp}\n```\n{cdata}\n```\n\n"
        except:
            die(f"failed to read context file: {cp}")

    hc_path = conf.get("HACKING_CONVENTIONS")
    hc_content = ""
    if hc_path and os.path.exists(hc_path):
        with open(hc_path, "r") as f:
            hc_content = f.read()

    tgt = "unknown"
    ext = os.path.splitext(outp)[1]
    base = os.path.basename(outp)

    lang_map_str = load_resource("languages.json", conf)
    if lang_map_str:
        lmap = json.loads(lang_map_str)
        if ext in lmap:
            tgt = lmap[ext]
        elif base in lmap:
            tgt = lmap[base]
        else:
            tgt = ext if ext else base

    tmpl = load_resource("prompt.tmpl", conf)

    gen_cmd = " ".join(sys.argv)
    if tgt in ["svg", "xml", "html"]:
        gen_cmd = gen_cmd.replace("--", "")

    ctx = {
        "generation_command": gen_cmd,
        "generation_config": json.dumps(redact_config(conf)),
        "target_language": tgt,
        "output_path": outp,
        "english_content": english_content,
        "hacking_conventions": hc_content,
        "context_files": ctx_files_str,
    }

    prompt = render_template(tmpl, ctx)
    LOGGER.write(f"prompt: {prompt}")

    print(f"transpiling '{inp}' to '{outp}' ({tgt})")

    iterations = int(conf.get("TEST_ITERATIONS", 3))
    test_cmd = conf.get("TEST_COMMAND")

    current_prompt = prompt

    for i in range(iterations):
        code = prov.call(current_prompt)

        lines = code.split("\n")
        if lines and lines[0].strip().startswith("```"):
            lines = lines[1:]
        if lines and lines[-1].strip().startswith("```"):
            lines = lines[:-1]
        clean_code = "\n".join(lines)

        try:
            with open(outp, "w") as f:
                f.write(clean_code)
        except Exception as e:
            die(f"failed to write output: {e}")

        if not test_cmd:
            print(f"successfully transpiled '{outp}'")
            break

        print(f"executing test command (`{test_cmd}`), attempt {i+1}/{iterations}")

        env = {}
        for k in ["PATH", "RUSTUP_HOME", "CARGO_HOME"]:
            if k in os.environ:
                env[k] = os.environ[k]

        try:
            proc = subprocess.run(
                test_cmd,
                shell=True,
                env=env,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
            )

            if proc.returncode == 0:
                print("test command succeeded!")
                break
            else:
                print("test command failed, see log for details")
                stdout = proc.stdout.decode("utf-8", errors="replace")
                stderr = proc.stderr.decode("utf-8", errors="replace")
                LOGGER.write(f"test failed:\nstdout:\n{stdout}\nstderr:\n{stderr}")

                retry_ctx = f"\n\nPREVIOUS ATTEMPT:\n```\n{clean_code}\n```\n\nTEST COMMAND: {test_cmd}\nEXIT CODE: {proc.returncode}\n\nOUTPUT:\n{stdout}\n{stderr}\n\nPlease fix the code based on these errors."
                current_prompt += retry_ctx

                if i == iterations - 1:
                    die("max test iterations reached")

        except Exception as e:
            die(f"error running test: {e}")

    print("--- api cost summary ---")
    pdata = get_pricing(prov.model, conf)

    in_t = prov.tokens["input"]
    out_t = prov.tokens["output"]
    think_t = prov.tokens["thinking"]

    print(f"tokens: {in_t} input, {out_t} output, {think_t} thinking")

    cost_in = 0.0
    cost_out = 0.0
    if pdata:
        cost_in = in_t * pdata.get("input_cost_per_token", 0)
        cost_out = out_t * pdata.get("output_cost_per_token", 0)

    print("estimated cost:")
    print(f"  - input   : ${cost_in:.6f}")
    print(f"  - output  : ${cost_out:.6f}")
    print(f"  - thinking: $0.000000")
    print(f"total: ${cost_in + cost_out:.6f}")


if __name__ == "__main__":
    main()
