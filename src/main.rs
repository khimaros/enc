// automatically generated by https://github.com/khimaros/enc using the following invocation: ./enc-release src/enc.en -o src/main.rs --context-files ./.enc.env.example:./Cargo.toml

use anyhow::{anyhow, Context, Result};
use chrono::Local;
use clap::{Arg, ArgAction, Command};
use futures::StreamExt;
use lazy_static::lazy_static;
use rand::{Rng, SeedableRng};
use regex::Regex;
use serde::{Deserialize, Serialize};
use serde_json::{json, Value};
use std::collections::{BTreeMap, HashMap};
use std::env;
use std::fs::{self, File, OpenOptions};
use std::io::{BufRead, BufReader, Write};
use std::path::{Path, PathBuf};
use std::time::Duration;

// "only for compiled languages, as a final fallback, compile-time macros are used to embed the actual resource files"
const EMBEDDED_LANGUAGES: &str = include_str!("../res/languages.json");
const EMBEDDED_PRICING: &str = include_str!("../res/pricing.json");
const EMBEDDED_PROMPT: &str = include_str!("../res/prompt.tmpl");

// "enc uses a layered configuration"
#[derive(Debug, Clone, Serialize)]
struct Config {
    provider: String,
    model: String,
    max_tokens: Option<u32>,
    thinking_budget: u32,
    seed: Option<i64>,
    hacking_conventions: String,
    timeout: u64,
    context_files: String,
    gemini_api_key: Option<String>,
    anthropic_api_key: Option<String>,
    openai_api_key: Option<String>,
    openai_api_base: String,
    logs_path: String,
    resources_path: String,
    test_command: String,
    test_iterations: usize,

    #[serde(skip)]
    input_file: Option<String>,
    #[serde(skip)]
    output_file: Option<String>,
    #[serde(skip)]
    show_config: bool,
}

#[derive(Debug, Default)]
struct ApiCost {
    tokens_in: u32,
    tokens_out: u32,
    tokens_think: u32,
    cost_in: f64,
    cost_out: f64,
    cost_think: f64,
}

// "pricing data for language model api calls is shown after the call completes, based on the pricing data"
#[allow(dead_code)]
#[derive(Debug, Deserialize)]
struct PricingModel {
    input_cost_per_token: f64,
    #[serde(default)]
    input_cost_per_token_above_200k_tokens: Option<f64>,
    #[serde(default)]
    output_cost_per_token: f64,
    #[serde(default)]
    output_cost_per_token_above_200k_tokens: Option<f64>,
    #[serde(default)]
    max_tokens: u32,
    #[serde(default)]
    max_input_tokens: u32,
}

lazy_static! {
    static ref RE_ENV_VAR: Regex = Regex::new(r"^\s*([A-Z_][A-Z0-9_]*)\s*=\s*(.*)$").unwrap();
}

// "each invocation of enc creates a new log file in the directory specified by the logs_path setting"
struct Logger {
    path: PathBuf,
}

impl Logger {
    fn new(dir: &str) -> Result<Self> {
        let timestamp = Local::now().format("%Y%m%d_%H%M%S");
        let path = Path::new(dir).join(format!("{}.log", timestamp));
        if let Some(parent) = path.parent() {
            fs::create_dir_all(parent)?;
        }
        Ok(Self { path })
    }

    fn log(&self, content: &str) {
        if let Ok(mut file) = OpenOptions::new()
            .create(true)
            .append(true)
            .open(&self.path)
        {
            let _ = writeln!(file, "{}", content);
        }
    }

    // "api keys are redacted from the log output and replaced with [redacted]"
    fn redact_and_log(&self, content: &str, keys: &[&Option<String>]) {
        let mut redacted = content.to_string();
        for key in keys {
            if let Some(k) = key {
                if !k.is_empty() {
                    redacted = redacted.replace(k, "[REDACTED]");
                }
            }
        }
        self.log(&redacted);
    }
}

// "when no model is explicitly specified, enc uses provider-specific defaults"
fn get_default_model(provider: &str) -> String {
    match provider {
        "google" => "gemini-2.5-pro".to_string(),
        "anthropic" => "claude-sonnet-4-20250514".to_string(),
        "openai" => "gpt-5-2025-08-07".to_string(),
        _ => "gpt-4o-mini".to_string(),
    }
}

// "configuration from sources with higher precedence override values from sources with lower precedence"
fn load_config() -> Result<Config> {
    let args = parse_args();

    // load envs manually to check keys without polluting actual env
    let home_env = dirs::home_dir().map(|h| h.join(".enc.env"));
    let work_env = PathBuf::from(".enc.env");

    let mut config_map = HashMap::new();

    // defaults
    config_map.insert("PROVIDER".to_string(), "google".to_string());
    config_map.insert(
        "HACKING_CONVENTIONS".to_string(),
        "./HACKING.md".to_string(),
    );
    config_map.insert("TIMEOUT".to_string(), "1800".to_string());
    config_map.insert("LOGS_PATH".to_string(), "./log/".to_string());
    config_map.insert(
        "RESOURCES_PATH".to_string(),
        "./res/:${XDG_DATA_HOME}/enc/res/".to_string(),
    );
    config_map.insert("TEST_ITERATIONS".to_string(), "3".to_string());
    config_map.insert("THINKING_BUDGET".to_string(), "2048".to_string());

    // load from .enc.env files
    let load_env_file = |path: PathBuf, map: &mut HashMap<String, String>| {
        if path.exists() {
            if let Ok(file) = File::open(path) {
                for line in BufReader::new(file).lines().flatten() {
                    if let Some(caps) = RE_ENV_VAR.captures(&line) {
                        let key = caps.get(1).unwrap().as_str().to_string();
                        let val = caps
                            .get(2)
                            .unwrap()
                            .as_str()
                            .trim_matches('"')
                            .trim_matches('\'')
                            .to_string();
                        if !key.starts_with('#') {
                            map.insert(key, val);
                        }
                    }
                }
            }
        }
    };

    if let Some(p) = home_env {
        load_env_file(p, &mut config_map);
    }
    load_env_file(work_env, &mut config_map);

    // env vars override files
    for (key, val) in env::vars() {
        config_map.insert(key, val);
    }

    // flags override envs
    let get_str = |key: &str, flag: Option<&String>| -> Option<String> {
        flag.cloned()
            .or_else(|| config_map.get(key).cloned())
            .filter(|s| !s.is_empty())
    };

    let get_u32 = |key: &str| -> Option<u32> { config_map.get(key).and_then(|s| s.parse().ok()) };

    let get_u64 = |key: &str| -> Option<u64> { config_map.get(key).and_then(|s| s.parse().ok()) };

    let provider = get_str("PROVIDER", args.get_one("provider")).unwrap_or("google".into());

    let model_raw = get_str("MODEL", args.get_one("model"));
    let model = model_raw.unwrap_or_else(|| get_default_model(&provider));

    let max_tokens = args
        .get_one::<String>("max_tokens")
        .and_then(|s| s.parse().ok())
        .or_else(|| get_u32("MAX_TOKENS"));

    let thinking_budget = args
        .get_one::<String>("thinking_budget")
        .and_then(|s| s.parse().ok())
        .or_else(|| get_u32("THINKING_BUDGET"))
        .unwrap_or(2048);

    let seed = args
        .get_one::<String>("seed")
        .and_then(|s| s.parse::<i64>().ok())
        .or_else(|| config_map.get("SEED").and_then(|s| s.parse().ok()));

    let hacking =
        get_str("HACKING_CONVENTIONS", args.get_one("hacking_conventions")).unwrap_or("".into());
    let timeout = args
        .get_one::<String>("timeout")
        .and_then(|s| s.parse().ok())
        .or_else(|| get_u64("TIMEOUT"))
        .unwrap_or(1800);

    let context_files = get_str("CONTEXT_FILES", args.get_one("context_files")).unwrap_or_default();

    Ok(Config {
        provider,
        model,
        max_tokens,
        thinking_budget,
        seed,
        hacking_conventions: hacking,
        timeout,
        context_files,
        gemini_api_key: get_str("GEMINI_API_KEY", None),
        anthropic_api_key: get_str("ANTHROPIC_API_KEY", None),
        openai_api_key: get_str("OPENAI_API_KEY", None),
        openai_api_base: get_str("OPENAI_API_BASE", None).unwrap_or_default(),
        logs_path: get_str("LOGS_PATH", None).unwrap_or("./log/".into()),
        resources_path: get_str("RESOURCES_PATH", None).unwrap_or("./res/".into()),
        test_command: get_str("TEST_COMMAND", args.get_one("test_command")).unwrap_or_default(),
        test_iterations: args
            .get_one::<String>("test_iterations")
            .and_then(|s| s.parse().ok())
            .or_else(|| {
                config_map
                    .get("TEST_ITERATIONS")
                    .and_then(|s| s.parse().ok())
            })
            .unwrap_or(3),
        input_file: args.get_one::<String>("input_file").cloned(),
        output_file: args.get_one::<String>("output_file").cloned(),
        show_config: args.get_flag("show_config"),
    })
}

// "when using a flag parsing library, all short flags are explicitly defined"
fn parse_args() -> clap::ArgMatches {
    Command::new("enc")
        .version("0.6.0")
        .arg(Arg::new("input_file").help("input .en file").index(1))
        .arg(
            Arg::new("output_file")
                .short('o')
                .long("output")
                .help("output file"),
        )
        .arg(
            Arg::new("provider")
                .short('p')
                .long("provider")
                .help("api provider"),
        )
        .arg(
            Arg::new("model")
                .short('m')
                .long("model")
                .help("model name"),
        )
        .arg(
            Arg::new("max_tokens")
                .long("max-tokens")
                .help("max output tokens"),
        )
        .arg(
            Arg::new("thinking_budget")
                .long("thinking-budget")
                .help("thinking budget tokens"),
        )
        .arg(Arg::new("seed").short('s').long("seed").help("rng seed"))
        .arg(
            Arg::new("hacking_conventions")
                .long("hacking-conventions")
                .help("path to hacking conventions"),
        )
        .arg(
            Arg::new("timeout")
                .long("timeout")
                .help("request timeout seconds"),
        )
        .arg(
            Arg::new("context_files")
                .short('c')
                .long("context-files")
                .help("colon separated context files"),
        )
        .arg(
            Arg::new("test_command")
                .short('t')
                .long("test-command")
                .help("command to run after transpilation"),
        )
        .arg(
            Arg::new("test_iterations")
                .long("test-iterations")
                .help("max retry iterations"),
        )
        .arg(
            Arg::new("show_config")
                .long("show-config")
                .action(ArgAction::SetTrue)
                .help("show config and exit"),
        )
        .get_matches()
}

// "enc searches for resource files ... in a specific order"
fn load_resource(path_list: &str, filename: &str, embedded: &str) -> String {
    let xdg_data = env::var("XDG_DATA_HOME").unwrap_or_else(|_| {
        dirs::home_dir()
            .map(|h| h.join(".local/share").to_string_lossy().into_owned())
            .unwrap_or_default()
    });

    for path in path_list.split(':') {
        let expanded = path.replace("${XDG_DATA_HOME}", &xdg_data);
        let full_path = Path::new(&expanded).join(filename);
        if full_path.exists() {
            if let Ok(content) = fs::read_to_string(full_path) {
                return content;
            }
        }
    }
    embedded.to_string()
}

#[tokio::main]
async fn main() -> Result<()> {
    // "when the --show-config flag is provided, enc first loads all sources of configuration... writes the redacted config"
    let config = load_config()?;

    if config.show_config {
        let mut redacted = config.clone();
        redacted.gemini_api_key = redacted.gemini_api_key.map(|_| "[REDACTED]".into());
        redacted.anthropic_api_key = redacted.anthropic_api_key.map(|_| "[REDACTED]".into());
        redacted.openai_api_key = redacted.openai_api_key.map(|_| "[REDACTED]".into());

        // lexically sorted output
        let json_val = serde_json::to_value(&redacted)?;
        if let Value::Object(map) = json_val {
            let sorted: BTreeMap<_, _> = map.into_iter().collect();
            println!("{}", serde_json::to_string_pretty(&sorted)?);
        }
        return Ok(());
    }

    if config.input_file.is_none() || config.output_file.is_none() {
        eprintln!("error: input_file and output_file are required");
        std::process::exit(1);
    }

    let logger = Logger::new(&config.logs_path)?;
    println!("debug log path: {}", logger.path.display());

    let _ = run_transpilation(&config, &logger).await.map_err(|e| {
        // "if an error occurs ... the error is printed to the console"
        eprintln!("error: {:#}", e);
        logger.log(&format!("error: {:#}", e));
        std::process::exit(1);
    });

    Ok(())
}

// "enc supports iterative refinement through automated testing"
async fn run_transpilation(config: &Config, logger: &Logger) -> Result<()> {
    let input_path = config.input_file.as_ref().unwrap();
    let output_path = config.output_file.as_ref().unwrap();

    println!("provider: {}, model: {}", config.provider, config.model);
    println!(
        "transpiling '{}' to '{}' ({})",
        input_path,
        output_path,
        detect_lang(output_path)
    );

    let prompt_tmpl = load_resource(&config.resources_path, "prompt.tmpl", EMBEDDED_PROMPT);
    let english_content =
        fs::read_to_string(input_path).with_context(|| format!("failed to read {}", input_path))?;

    let mut total_cost = ApiCost::default();
    let mut iterations = 0;
    let has_test = !config.test_command.is_empty();
    let max_iterations = if has_test { config.test_iterations } else { 0 };

    let mut test_context = String::new();

    loop {
        // "template expansion is done once as a single pass"
        let prompt = render_prompt(&prompt_tmpl, config, &english_content, &test_context)?;

        logger.redact_and_log(
            &format!("prompt:\n{}", prompt),
            &[
                &config.gemini_api_key,
                &config.anthropic_api_key,
                &config.openai_api_key,
            ],
        );

        let (content, usage) = call_provider(config, &config.model, &prompt, logger).await?;

        total_cost.tokens_in += usage.tokens_in;
        total_cost.tokens_out += usage.tokens_out;
        total_cost.tokens_think += usage.tokens_think;
        total_cost.cost_in += usage.cost_in;
        total_cost.cost_out += usage.cost_out;
        total_cost.cost_think += usage.cost_think;

        if content.trim().is_empty() {
            return Err(anyhow!("llm returned empty response"));
        }

        // "markdown code fences will only be removed from the very first and very last lines"
        let clean_content = remove_fences(&content);

        if let Some(parent) = Path::new(output_path).parent() {
            fs::create_dir_all(parent)?;
        }
        fs::write(output_path, &clean_content)?;
        println!("successfully transpiled '{}'", output_path);

        if has_test {
            if iterations >= max_iterations {
                if iterations > 0 {
                    eprintln!("test command failed after {} iterations", iterations);
                    print_cost(&total_cost);
                    std::process::exit(1);
                }
                break;
            }

            iterations += 1;
            println!(
                "executing test command (`{}`), attempt {}/{}",
                config.test_command, iterations, max_iterations
            );

            match run_test_command(&config.test_command) {
                Ok(_) => {
                    println!("test command succeeded!");
                    break;
                }
                Err((code, output)) => {
                    println!("test command failed, see log for details");
                    logger.log(&format!(
                        "test failure:\ncode: {}\noutput:\n{}",
                        code, output
                    ));

                    test_context = format!(
                        "\n\nPREVIOUS GENERATION:\n```\n{}\n```\n\nTEST COMMAND: `{}`\nEXIT CODE: {}\n\nTEST OUTPUT:\n{}",
                        clean_content, config.test_command, code, output
                    );
                }
            }
        } else {
            break;
        }
    }

    print_cost(&total_cost);
    Ok(())
}

// "remove dead code and unnecessary or obvious comments"
fn remove_fences(s: &str) -> String {
    let lines: Vec<&str> = s.lines().collect();
    if lines.is_empty() {
        return s.to_string();
    }

    let start = if lines[0].trim().starts_with("```") {
        1
    } else {
        0
    };
    let mut end = lines.len();
    if end > start && lines[end - 1].trim().starts_with("```") {
        end -= 1;
    }

    lines[start..end].join("\n") + "\n"
}

// "code generation ... target language name is loaded from ./res/languages.json"
fn detect_lang(path: &str) -> String {
    let langs_json = load_resource("", "languages.json", EMBEDDED_LANGUAGES);
    let map: HashMap<String, String> = serde_json::from_str(&langs_json).unwrap_or_default();

    let path_obj = Path::new(path);
    let ext = path_obj
        .extension()
        .map(|e| format!(".{}", e.to_string_lossy()));
    let name = path_obj
        .file_name()
        .map(|n| n.to_string_lossy().to_string());

    if let Some(e) = ext {
        if let Some(l) = map.get(&e) {
            return l.clone();
        }
        return e;
    }
    if let Some(n) = name {
        if let Some(l) = map.get(&n) {
            return l.clone();
        }
        return n;
    }
    "unknown".to_string()
}

// "the prompt template is loaded ... template variables are written between double curly braces"
fn render_prompt(tmpl: &str, config: &Config, english: &str, test_ctx: &str) -> Result<String> {
    let target_lang = detect_lang(config.output_file.as_ref().unwrap());
    let output_path = config.output_file.as_ref().unwrap();

    // "generation_command: the command line args enc was called with"
    let args: Vec<String> = env::args().collect();
    let mut cmd_str = args.join(" ");

    // "if the target format is a derivative of xml ... strip all double-hyphens"
    let is_xml = ["svg", "xml", "html"]
        .iter()
        .any(|&x| target_lang.contains(x) || output_path.ends_with(x));
    if is_xml {
        cmd_str = cmd_str.replace("--", "");
    }

    let mut redacted_config = config.clone();
    redacted_config.gemini_api_key = None;
    redacted_config.anthropic_api_key = None;
    redacted_config.openai_api_key = None;

    let config_json = {
        let v = serde_json::to_value(&redacted_config)?;
        if let Value::Object(map) = v {
            let sorted: BTreeMap<_, _> = map.into_iter().collect();
            serde_json::to_string_pretty(&sorted)?
        } else {
            serde_json::to_string_pretty(&redacted_config)?
        }
    };

    let hacking = if !config.hacking_conventions.is_empty() {
        match fs::read_to_string(&config.hacking_conventions) {
            Ok(c) => c,
            Err(_) => String::new(), // "if ... not present ... empty"
        }
    } else {
        String::new()
    };

    let mut ctx_str = String::new();
    let files: Vec<&str> = if config.context_files.is_empty() {
        Vec::new()
    } else {
        config.context_files.split(':').collect()
    };

    for f in files {
        let content =
            fs::read_to_string(f).with_context(|| format!("failed to read context file {}", f))?;
        ctx_str.push_str(&format!("\n### {}\n```\n{}\n```\n", f, content));
    }

    let mut full_english = english.to_string();
    if !test_ctx.is_empty() {
        full_english.push_str(test_ctx);
    }

    let mut prompt = tmpl.to_string();
    let replacements = [
        ("generation_command", cmd_str),
        ("generation_config", config_json),
        ("target_language", target_lang),
        ("output_path", output_path.to_string()),
        ("english_content", full_english),
        ("hacking_conventions", hacking),
        ("context_files", ctx_str),
    ];

    for (k, v) in replacements {
        prompt = prompt.replace(&format!("{{{{{}}}}}", k), &v);
    }

    Ok(prompt)
}

// "test command is executed with a restricted environment"
fn run_test_command(cmd: &str) -> Result<(), (i32, String)> {
    let whitelist = ["PATH", "RUSTUP_HOME", "CARGO_HOME"];
    let mut command = std::process::Command::new("sh");
    command.arg("-c").arg(cmd);

    command.env_clear();
    for key in whitelist {
        if let Ok(val) = env::var(key) {
            command.env(key, val);
        }
    }

    let output = command.output().map_err(|e| (-1, e.to_string()))?;

    if output.status.success() {
        Ok(())
    } else {
        let stdout = String::from_utf8_lossy(&output.stdout);
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err((
            output.status.code().unwrap_or(-1),
            format!("STDOUT:\n{}\nSTDERR:\n{}", stdout, stderr),
        ))
    }
}

// "calculating costs ... based on the pricing data in ./res/pricing.json"
fn calculate_cost(model: &str, pricing_json: &str, usage: &mut ApiCost) {
    let map: HashMap<String, PricingModel> = serde_json::from_str(pricing_json).unwrap_or_default();

    // "if token cost data is not available, a warning will be printed"
    let pricing = map
        .get(model)
        .or_else(|| map.iter().find(|(k, _)| k.ends_with(model)).map(|(_, v)| v));

    if let Some(p) = pricing {
        let in_cost =
            if usage.tokens_in > 200_000 && p.input_cost_per_token_above_200k_tokens.is_some() {
                p.input_cost_per_token
            } else {
                p.input_cost_per_token
            };

        usage.cost_in = (usage.tokens_in as f64) * in_cost;
        usage.cost_out = (usage.tokens_out as f64) * p.output_cost_per_token;
        usage.cost_think = (usage.tokens_think as f64) * p.output_cost_per_token;
    } else {
        eprintln!("warning: pricing data not found for model {}", model);
    }
}

async fn call_provider(
    config: &Config,
    model: &str,
    prompt: &str,
    logger: &Logger,
) -> Result<(String, ApiCost)> {
    let client = reqwest::Client::builder()
        .timeout(Duration::from_secs(config.timeout))
        .build()?;

    match config.provider.as_str() {
        "google" => call_google(client, config, model, prompt, logger).await,
        "anthropic" => call_anthropic(client, config, model, prompt, logger).await,
        _ => call_openai(client, config, model, prompt, logger).await,
    }
}

async fn call_google(
    client: reqwest::Client,
    config: &Config,
    model: &str,
    prompt: &str,
    logger: &Logger,
) -> Result<(String, ApiCost)> {
    let key = config
        .gemini_api_key
        .as_ref()
        .ok_or(anyhow!("missing GEMINI_API_KEY"))?;
    let url = format!(
        "https://generativelanguage.googleapis.com/v1beta/models/{}:generateContent?key={}",
        model, key
    );

    let generation_config = if let Some(_) = config.seed {
        json!({ "temperature": 0.0 })
    } else {
        json!({})
    };

    let body = json!({
        "contents": [{ "parts": [{ "text": prompt }] }],
        "generationConfig": generation_config
    });

    let res = client.post(&url).json(&body).send().await?;
    let status = res.status();
    if !status.is_success() {
        let err_text = res.text().await?;
        return Err(anyhow!("api error {}: {}", status, err_text));
    }

    let json: Value = res.json().await?;
    logger.redact_and_log(&format!("response: {}", json), &[&Some(key.clone())]);

    let mut content = String::new();
    if let Some(candidates) = json["candidates"].as_array() {
        if let Some(first) = candidates.first() {
            if let Some(parts) = first["content"]["parts"].as_array() {
                for part in parts {
                    if let Some(text) = part["text"].as_str() {
                        content.push_str(text);
                    }
                }
            }
        }
    }

    let mut cost = ApiCost::default();
    if let Some(usage) = json["usageMetadata"].as_object() {
        cost.tokens_in = usage
            .get("promptTokenCount")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32;
        cost.tokens_out = usage
            .get("candidatesTokenCount")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32;
        cost.tokens_think = (usage
            .get("totalTokenCount")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32)
            .saturating_sub(cost.tokens_in + cost.tokens_out);
    }

    let pricing_json = load_resource(&config.resources_path, "pricing.json", EMBEDDED_PRICING);
    calculate_cost(&format!("google/{}", model), &pricing_json, &mut cost);

    Ok((content, cost))
}

async fn call_anthropic(
    client: reqwest::Client,
    config: &Config,
    model: &str,
    prompt: &str,
    logger: &Logger,
) -> Result<(String, ApiCost)> {
    let key = config
        .anthropic_api_key
        .as_ref()
        .ok_or(anyhow!("missing ANTHROPIC_API_KEY"))?;
    let url = "https://api.anthropic.com/v1/messages";

    let mut body_map = serde_json::Map::new();
    body_map.insert("model".to_string(), json!(model));
    body_map.insert(
        "max_tokens".to_string(),
        json!(config.max_tokens.unwrap_or(8192)),
    );
    body_map.insert(
        "messages".to_string(),
        json!([{ "role": "user", "content": prompt }]),
    );
    body_map.insert("stream".to_string(), json!(true));

    if config.thinking_budget > 0 {
        body_map.insert(
            "thinking".to_string(),
            json!({
                "type": "enabled",
                "budget_tokens": config.thinking_budget
            }),
        );
        body_map.insert("temperature".to_string(), json!(1.0));
    } else if config.seed.is_some() {
        body_map.insert("temperature".to_string(), json!(0.0));
    }

    let req = client
        .post(url)
        .header("x-api-key", key)
        .header("anthropic-version", "2023-06-01")
        .json(&Value::Object(body_map));

    let mut stream = req.send().await?.bytes_stream();

    let mut full_content = String::new();
    let mut cost = ApiCost::default();
    let mut buffer = String::new();

    while let Some(item) = stream.next().await {
        let chunk = item?;
        let s = String::from_utf8_lossy(&chunk);
        buffer.push_str(&s);

        while let Some(idx) = buffer.find('\n') {
            let line = buffer[..idx].trim().to_string();
            buffer = buffer[idx + 1..].to_string();

            if line.starts_with("data: ") {
                let data = &line[6..];
                if data == "[DONE]" {
                    continue;
                }

                if let Ok(event) = serde_json::from_str::<Value>(data) {
                    let event_type = event["type"].as_str().unwrap_or("");

                    match event_type {
                        "message_start" => {
                            if let Some(usage) = event["message"]["usage"].as_object() {
                                cost.tokens_in = usage
                                    .get("input_tokens")
                                    .and_then(|v| v.as_u64())
                                    .unwrap_or(0)
                                    as u32;
                            }
                        }
                        "content_block_delta" => {
                            if let Some(delta) = event["delta"].as_object() {
                                match delta.get("type").and_then(|s| s.as_str()) {
                                    Some("text_delta") => {
                                        if let Some(text) =
                                            delta.get("text").and_then(|s| s.as_str())
                                        {
                                            full_content.push_str(text);
                                            logger.log(&format!("text_delta: {}", text));
                                        }
                                    }
                                    Some("thinking_delta") => {
                                        if let Some(thinking) =
                                            delta.get("thinking").and_then(|s| s.as_str())
                                        {
                                            logger.log(&format!("thinking_delta: {}", thinking));
                                        }
                                    }
                                    Some("signature_delta") => {
                                        if let Some(sig) =
                                            delta.get("signature").and_then(|s| s.as_str())
                                        {
                                            logger.log(&format!("signature_delta: {}", sig));
                                        }
                                    }
                                    _ => {}
                                }
                            }
                        }
                        "message_delta" => {
                            if let Some(usage) = event["usage"].as_object() {
                                cost.tokens_out = usage
                                    .get("output_tokens")
                                    .and_then(|v| v.as_u64())
                                    .unwrap_or(0)
                                    as u32;
                            }
                        }
                        "error" => {
                            return Err(anyhow!("api stream error: {}", event));
                        }
                        _ => {}
                    }
                }
            }
        }
    }

    logger.redact_and_log(
        &format!("full response: {}", full_content),
        &[&Some(key.clone())],
    );

    let pricing_json = load_resource(&config.resources_path, "pricing.json", EMBEDDED_PRICING);
    calculate_cost(&format!("anthropic/{}", model), &pricing_json, &mut cost);

    Ok((full_content, cost))
}

async fn call_openai(
    client: reqwest::Client,
    config: &Config,
    model: &str,
    prompt: &str,
    logger: &Logger,
) -> Result<(String, ApiCost)> {
    let key = config
        .openai_api_key
        .as_ref()
        .ok_or(anyhow!("missing OPENAI_API_KEY"))?;
    let base = if config.openai_api_base.is_empty() {
        "https://api.openai.com/v1"
    } else {
        &config.openai_api_base
    };
    let url = format!("{}/chat/completions", base.trim_end_matches('/'));

    let mut body_map = serde_json::Map::new();
    body_map.insert("model".to_string(), json!(model));
    body_map.insert(
        "messages".to_string(),
        json!([{ "role": "user", "content": prompt }]),
    );

    let max_tokens_val = json!(config.max_tokens.unwrap_or(8192));
    if base.contains("api.openai.com") {
        body_map.insert("max_completion_tokens".to_string(), max_tokens_val);
    } else {
        body_map.insert("max_tokens".to_string(), max_tokens_val);
    }

    if let Some(seed) = config.seed {
        body_map.insert("seed".to_string(), json!(seed));
    } else {
        let mut rng = rand::rngs::StdRng::from_entropy();
        body_map.insert("seed".to_string(), json!(rng.gen::<i64>()));
    }

    let res = client
        .post(&url)
        .header("Authorization", format!("Bearer {}", key))
        .json(&Value::Object(body_map))
        .send()
        .await?;

    let status = res.status();
    if !status.is_success() {
        let err = res.text().await?;
        return Err(anyhow!("api error {}: {}", status, err));
    }

    let json: Value = res.json().await?;
    logger.redact_and_log(&format!("response: {}", json), &[&Some(key.clone())]);

    let content = json["choices"][0]["message"]["content"]
        .as_str()
        .unwrap_or("")
        .to_string();

    let mut cost = ApiCost::default();
    if let Some(usage) = json["usage"].as_object() {
        cost.tokens_in = usage
            .get("prompt_tokens")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32;
        cost.tokens_out = usage
            .get("completion_tokens")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32;

        // "in these cases, thinking token counts will be calculated using the formula"
        let total = usage
            .get("total_tokens")
            .and_then(|v| v.as_u64())
            .unwrap_or(0) as u32;
        if total > cost.tokens_in + cost.tokens_out {
            cost.tokens_think = total - cost.tokens_in - cost.tokens_out;
        }
    }

    let pricing_json = load_resource(&config.resources_path, "pricing.json", EMBEDDED_PRICING);
    calculate_cost(model, &pricing_json, &mut cost);

    Ok((content, cost))
}

fn print_cost(cost: &ApiCost) {
    println!("\n--- api cost summary ---");
    println!(
        "tokens: {} input, {} output, {} thinking",
        cost.tokens_in, cost.tokens_out, cost.tokens_think
    );
    println!("estimated cost:");
    println!("  - input   : ${:.6}", cost.cost_in);
    println!("  - output  : ${:.6}", cost.cost_out);
    if cost.tokens_think > 0 {
        println!("  - thinking: ${:.6}", cost.cost_think);
    }
    println!(
        "total: ${:.6}",
        cost.cost_in + cost.cost_out + cost.cost_think
    );
}
