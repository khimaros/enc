#!/usr/bin/env python3
# NOTICE: this file was automatically generated by https://github.com/khimaros/enc using the following invocation:
# ./enc-release scripts/pricing.en -o scripts/pricing.py --context-files ./res/pricing.json

import json
import sys
from pathlib import Path
from urllib.request import urlopen

# keep dependencies to a minimum and prefer standard library.
# with python, json5 should be used to parse the source data.
try:
    import json5
except ImportError:
    print("error: json5 is not installed. please run `pip install json5`", file=sys.stderr)
    sys.exit(1)

# the source url is: https://raw.githubusercontent.com/Aider-AI/aider/refs/heads/main/aider/resources/model-metadata.json
SOURCE_URL = "https://raw.githubusercontent.com/Aider-AI/aider/refs/heads/main/aider/resources/model-metadata.json"
# the resulting data should be written to ./res/pricing.json
OUTPUT_FILE = Path(__file__).parent.parent / "res" / "pricing.json"

# those objects have many keys, but will be filtered to have only the following ones:
# - max_tokens
# - max_input_tokens
# - input_cost_per_token
# - input_cost_per_token_above_200k_tokens
# - output_cost_per_token
# - output_cost_per_token_above_200k_tokens
# - source
ALLOWED_KEYS = {
    "max_tokens",
    "max_input_tokens",
    "input_cost_per_token",
    "input_cost_per_token_above_200k_tokens",
    "output_cost_per_token",
    "output_cost_per_token_above_200k_tokens",
    "source",
}


# this script downloads and converts pricing data from aider
def download_data(url):
    """downloads data from the given url."""
    print(f"downloading from {url}...")
    with urlopen(url) as response:
        return response.read().decode("utf-8")


# in general, the JSON parsing is extremely permissive to well formedness issues.
# with python, json5 should be used to parse the source data.
def parse_data(content):
    """parses json5 content."""
    return json5.loads(content)


# the base JSON is an object and the keys are of the form "<provider>/<model>"
# each key of that form has a value of which is an object.
# there will be many models in the source data and they should all be converted.
def process_data(source_data):
    """processes the raw data into the desired format."""
    processed = {}
    for key, value in source_data.items():
        # if there is an extra "openrouter/" prefix, it should be removed.
        if key.startswith("openrouter/"):
            key = key[len("openrouter/") :]

        # if no provider is specified, that entire object should be skipped.
        if "/" not in key:
            continue

        provider, model_name = key.split("/", 1)

        # where provider is "gemini", it will be replaced with "google"
        if provider == "gemini":
            provider = "google"

        new_key = f"{provider}/{model_name}"
        # not all objects contain all of the keys listed here.
        new_value = {k: v for k, v in value.items() if k in ALLOWED_KEYS}

        if new_value:
            processed[new_key] = new_value

    return processed


# the resulting data should be written to ./res/pricing.json
def write_output(data, file_path):
    """writes the processed data to a json file."""
    print(f"writing to {file_path}...")
    file_path.parent.mkdir(parents=True, exist_ok=True)
    with open(file_path, "w") as f:
        json.dump(data, f, indent=4, sort_keys=True)
        f.write("\n")


def main():
    """main entry point for the script."""
    content = download_data(SOURCE_URL)
    source_data = parse_data(content)
    # and it should be converted to look like: ...
    processed_data = process_data(source_data)
    write_output(processed_data, OUTPUT_FILE)
    print("done.")


if __name__ == "__main__":
    main()