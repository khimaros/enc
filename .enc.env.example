# language model API provider: "google", "anthropic", or "openai"
#PROVIDER="google"

# model to use for inference
#MODEL="gemini-2.5-pro"

# maximum number of tokens for the LLM to generatA (defaults to model max)
#MAX_TOKENS=

# maximum tokens for deep thought
#THINKING_BUDGET=2048

# grounded mode adds the existing code (if present) to context files
#GROUNDED_MODE=false

# seed used for inference (empty means random)
#SEED=

# coding conventions and style guide
#HACKING_CONVENTIONS="./HACKING.md"

# additional file paths to include as context (colon separated)
#CONTEXT_FILES=

# endpoint configuration
#GEMINI_API_KEY=
#OPENAI_API_KEY=
#OPENAI_API_BASE=

# path to store API logs
#LOGS_PATH="./log/"

# path to the code generation prompt template
#PROMPT_TEMPLATE_PATH="./res/prompt.tmpl"

# path to the pricing data json file
#PRICING_DATA_PATH="./res/pricing.json"
