# language model API provider: "google", "anthropic", or "openai"
#PROVIDER="google"

# model to use for inference (gemini-2.5-pro, claude-sonnet-4-20250514, gpt-4o-mini)
#MODEL="gemini-2.5-pro"

# maximum number of tokens for the LLM to generatA (defaults to model max)
#MAX_TOKENS=

# maximum tokens for deep thought
#THINKING_BUDGET=2048

# seed used for inference (empty means random)
#SEED=

# coding conventions and style guide
#HACKING_CONVENTIONS="./HACKING.md"

# timeout for API requests
#TIMEOUT=1800

# additional file paths to include as context (colon separated)
#CONTEXT_FILES=

# endpoint configuration
#GEMINI_API_KEY=
#ANTHROPIC_API_KEY=
#OPENAI_API_KEY=
# for example "http://localhost:7860/v1"
#OPENAI_API_BASE=

# path to store API logs
#LOGS_PATH="./log/"

# path to resources (pricing, language map, templates)
#RESOURCES_PATH="./res/:${XDG_DATA_HOME}/enc/res/"

# command to run after transpilation
#TEST_COMMAND=

# number of times to attempt transpilation if test command fails
#TEST_ITERATIONS=3
